#!/usr/bin/env python3
"""
Test script to verify connection to remote Ollama server
"""

import asyncio
import httpx
import json
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

OLLAMA_URL = os.getenv("OLLAMA_URL", "http://olla.hcmutertic.com")
AI_MODEL = os.getenv("AI_MODEL", "deepseek-r1:8b")

async def test_basic_connection():
    """Test basic connection to Ollama server"""
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(f"{OLLAMA_URL}/api/tags")
            if response.status_code == 200:
                print("‚úÖ Basic connection successful")
                models = response.json()
                print(f"Available models: {[model['name'] for model in models.get('models', [])]}")
                return True
            else:
                print(f"‚ùå Connection failed with status: {response.status_code}")
                return False
    except Exception as e:
        print(f"‚ùå Connection error: {e}")
        return False

async def test_model_availability():
    """Test if the specified model is available"""
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(f"{OLLAMA_URL}/api/tags")
            if response.status_code == 200:
                models = response.json()
                available_models = [model['name'] for model in models.get('models', [])]
                
                if AI_MODEL in available_models:
                    print(f"‚úÖ Model '{AI_MODEL}' is available")
                    return True
                else:
                    print(f"‚ùå Model '{AI_MODEL}' not found")
                    print(f"Available models: {available_models}")
                    return False
    except Exception as e:
        print(f"‚ùå Model check error: {e}")
        return False

async def test_ai_generation():
    """Test AI model generation"""
    try:
        async with httpx.AsyncClient() as client:
            payload = {
                "model": AI_MODEL,
                "prompt": "Xin ch√†o, ƒë√¢y l√† tin nh·∫Øn test. H√£y tr·∫£ l·ªùi ng·∫Øn g·ªçn b·∫±ng ti·∫øng Vi·ªát.",
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "max_tokens": 100
                }
            }
            
            response = await client.post(
                f"{OLLAMA_URL}/api/generate",
                json=payload,
                timeout=30.0
            )
            
            if response.status_code == 200:
                result = response.json()
                print("‚úÖ AI generation successful")
                print(f"Response: {result.get('response', 'No response')[:100]}...")
                return True
            else:
                print(f"‚ùå AI generation failed with status: {response.status_code}")
                print(f"Response: {response.text}")
                return False
    except Exception as e:
        print(f"‚ùå AI generation error: {e}")
        return False

async def test_financial_analysis():
    """Test financial analysis with sample data"""
    try:
        async with httpx.AsyncClient() as client:
            # Sample financial data
            sample_data = {
                "total_income": 15000000,
                "total_expenses": 12000000,
                "category_spending": {
                    "ƒÇn u·ªëng": 4000000,
                    "Di chuy·ªÉn": 2000000,
                    "Nh√† c·ª≠a": 3000000,
                    "Gi·∫£i tr√≠": 1500000,
                    "Kh√°c": 1500000
                }
            }
            
            prompt = f"""
            Ph√¢n t√≠ch t√†i ch√≠nh c√° nh√¢n:
            
            T·ªïng thu nh·∫≠p: {sample_data['total_income']:,} VND
            T·ªïng chi ti√™u: {sample_data['total_expenses']:,} VND
            S·ªë d∆∞: {sample_data['total_income'] - sample_data['total_expenses']:,} VND
            
            Chi ti√™u theo danh m·ª•c:
            {json.dumps(sample_data['category_spending'], ensure_ascii=False, indent=2)}
            
            H√£y ƒë∆∞a ra ph√¢n t√≠ch ng·∫Øn g·ªçn v√† l·ªùi khuy√™n ti·∫øt ki·ªám.
            """
            
            payload = {
                "model": AI_MODEL,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "max_tokens": 300
                }
            }
            
            response = await client.post(
                f"{OLLAMA_URL}/api/generate",
                json=payload,
                timeout=60.0
            )
            
            if response.status_code == 200:
                result = response.json()
                print("‚úÖ Financial analysis test successful")
                print(f"Analysis: {result.get('response', 'No response')[:200]}...")
                return True
            else:
                print(f"‚ùå Financial analysis failed with status: {response.status_code}")
                return False
    except Exception as e:
        print(f"‚ùå Financial analysis error: {e}")
        return False

async def main():
    """Run all tests"""
    print("=" * 50)
    print("Testing Remote Ollama Server Connection")
    print("=" * 50)
    print(f"Server URL: {OLLAMA_URL}")
    print(f"AI Model: {AI_MODEL}")
    print()
    
    tests = [
        ("Basic Connection", test_basic_connection),
        ("Model Availability", test_model_availability),
        ("AI Generation", test_ai_generation),
        ("Financial Analysis", test_financial_analysis)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"Running {test_name}...")
        result = await test_func()
        results.append((test_name, result))
        print()
    
    # Summary
    print("=" * 50)
    print("Test Summary")
    print("=" * 50)
    
    passed = 0
    for test_name, result in results:
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print()
    print(f"Tests passed: {passed}/{len(results)}")
    
    if passed == len(results):
        print("üéâ All tests passed! Your setup is ready.")
        print("You can now run: start.bat")
    else:
        print("‚ö†Ô∏è  Some tests failed. Please check your configuration.")
    
    print("=" * 50)

if __name__ == "__main__":
    asyncio.run(main())
